import json
import re
import os
import time
from datetime import datetime
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
import matplotlib.pyplot as plt
from deep_translator import GoogleTranslator

# ==========================================
# 1. ç¿»è­¯èˆ‡å°ç…§è¨­å®š
# ==========================================

# åˆå§‹åŒ–ç¿»è­¯å™¨ (ç›®æ¨™èªè¨€ï¼šç¹é«”ä¸­æ–‡)
translator = GoogleTranslator(source='auto', target='zh-TW')

# ç¿»è­¯å¿«å–ï¼Œé¿å…é‡è¤‡è«‹æ±‚å°è‡´æ…¢æˆ–è¢«æ“‹
TRANSLATION_CACHE = {}

def auto_translate(text):
    """
    [New] è‡ªå‹•ç¿»è­¯åŠŸèƒ½
    ä½¿ç”¨ Google Translate å°‡è‹±æ–‡æè¿°è½‰ç‚ºç¹é«”ä¸­æ–‡
    """
    if not text or len(text) < 2:
        return text
        
    # å¦‚æœå·²ç¶“ç¿»è­¯éï¼Œç›´æ¥å›å‚³
    if text in TRANSLATION_CACHE:
        return TRANSLATION_CACHE[text]
    
    try:
        # é™åˆ¶é•·åº¦ä»¥å…ç¿»è­¯å¤±æ•—ï¼Œé€šå¸¸æè¿°ä¸æœƒè¶…é 4500 å­—å…ƒ
        translate_text = text[:4500]
        result = translator.translate(translate_text)
        TRANSLATION_CACHE[text] = result
        return result
    except Exception as e:
        print(f"âš ï¸ ç¿»è­¯å¤±æ•— (ä½¿ç”¨åŸæ–‡): {e}")
        return text

RISK_MAPPING = {
    "High": "é«˜é¢¨éšª (High)",
    "Medium": "ä¸­é¢¨éšª (Medium)",
    "Low": "ä½é¢¨éšª (Low)",
    "Informational": "è³‡è¨Š (Info)",
    "False Positive": "èª¤å ± (False Positive)"
}

TERM_MAPPING = {
    "Cross Site Scripting (Reflected)": "åå°„å‹è·¨ç«™è…³æœ¬æ”»æ“Š (XSS)",
    "Cross Site Scripting (Persistent)": "å„²å­˜å‹è·¨ç«™è…³æœ¬æ”»æ“Š (XSS)",
    "Cross Site Scripting (DOM Based)": "DOM å‹è·¨ç«™è…³æœ¬æ”»æ“Š (XSS)",
    "SQL Injection": "SQL è³‡æ–™éš±ç¢¼æ”»æ“Š",
    "Path Traversal": "è·¯å¾‘éæ­·æ¼æ´",
    "Remote File Inclusion": "é ç«¯æª”æ¡ˆåŒ…å« (RFI)",
    "Server Side Include": "ä¼ºæœå™¨ç«¯åŒ…å«æ³¨å…¥ (SSI)",
    "Cross-Site Request Forgery": "è·¨ç«™è«‹æ±‚å½é€  (CSRF)",
    "Directory Browsing": "ç›®éŒ„éæ­·/ç›®éŒ„ç€è¦½",
    "Buffer Overflow": "ç·©è¡å€æº¢ä½",
    "Format String Error": "æ ¼å¼åŒ–å­—ä¸²éŒ¯èª¤",
    "Information Disclosure - Debug Error Messages": "è³‡è¨Šæ´©æ¼ - åµéŒ¯éŒ¯èª¤è¨Šæ¯",
    "Information Disclosure - Sensitive Information in URL": "è³‡è¨Šæ´©æ¼ - URL åŒ…å«æ•æ„Ÿè³‡è¨Š",
    "Information Disclosure - Suspicious Comments": "è³‡è¨Šæ´©æ¼ - å¯ç–‘çš„ç¨‹å¼è¨»è§£",
    "Weak Authentication Method": "èº«åˆ†é©—è­‰æ©Ÿåˆ¶è–„å¼±",
    "Absence of Anti-CSRF Tokens": "ç¼ºä¹ Anti-CSRF Token",
    "Missing Anti-clickjacking Header": "éºå¤±é˜²é»æ“ŠåŠ«æŒæ¨™é ­ (Clickjacking)",
    "X-Frame-Options Header Not Set": "æœªè¨­å®š X-Frame-Options æ¨™é ­",
    "X-Content-Type-Options Header Missing": "éºå¤± X-Content-Type-Options æ¨™é ­",
    "Strict-Transport-Security Header Not Set": "æœªè¨­å®š HSTS å®‰å…¨å‚³è¼¸æ¨™é ­",
    "Cookie No HttpOnly Flag": "Cookie éºå¤± HttpOnly å±¬æ€§",
    "Cookie Without Secure Flag": "Cookie éºå¤± Secure å±¬æ€§",
    "Application Error Disclosure": "æ‡‰ç”¨ç¨‹å¼éŒ¯èª¤è³‡è¨Šæ­éœ²",
    "Private IP Disclosure": "å…§éƒ¨ IP ä½å€æ´©æ¼",
    "Session ID in URL Rewrite": "Session ID æš´éœ²æ–¼ URL",
    "Source Code Disclosure": "åŸå§‹ç¢¼æ´©æ¼",
}

# ==========================================
# 2. è¼”åŠ©å‡½å¼
# ==========================================

def clean_html(raw_html):
    if raw_html is None: return ""
    cleanr = re.compile('<.*?>')
    return re.sub(cleanr, '', raw_html).strip()

def translate_title(english_title):
    return TERM_MAPPING.get(english_title, english_title)

def set_table_header_style(cell):
    """è¨­å®šè¡¨æ ¼æ¨™é¡Œçš„åº•è‰²èˆ‡ç²—é«”"""
    paragraphs = cell.paragraphs
    for p in paragraphs:
        for run in p.runs:
            run.bold = True
            run.font.size = Pt(12)

def generate_risk_chart(stats, output_img_path):
    """ç¹ªè£½é¢¨éšªåˆ†ä½ˆåœ“é¤…åœ–"""
    labels = []
    sizes = []
    colors = []
    mapping = {
        "High": ("é«˜é¢¨éšª", "#ff0000"),
        "Medium": ("ä¸­é¢¨éšª", "#ffa500"),
        "Low": ("ä½é¢¨éšª", "#ffff00"),
        "Informational": ("è³‡è¨Š", "#0000ff")
    }
    for key, (label, color) in mapping.items():
        if stats[key] > 0:
            labels.append(f"{label} ({stats[key]})")
            sizes.append(stats[key])
            colors.append(color)
            
    if not sizes: return False

    plt.figure(figsize=(4, 3))
    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)
    plt.axis('equal')
    plt.title("å¼±é»é¢¨éšªåˆ†ä½ˆ", fontname="Microsoft JhengHei")
    plt.tight_layout()
    plt.savefig(output_img_path)
    plt.close()
    return True

def parse_ai_response(text):
    """æ™ºæ…§è§£æå™¨ï¼šå°‡ AI çš„ Markdown å›æ‡‰æ‹†è§£ç‚ºçµæ§‹åŒ–å€å¡Š"""
    sections = {'explanation': '', 'solution': '', 'reference': ''}
    current_section = None
    buffer = []
    lines = text.split('\n')
    header_regex = re.compile(r'^(#+\s*|\*\*)?(å¼±é»èªªæ˜|ä¿®å¾©å»ºè­°|è§£æ±ºæ–¹æ³•|åƒè€ƒè³‡æ–™|Explanation|Solution|Reference)([:ï¼š])?(\*\*)?\s*$')

    for line in lines:
        stripped = line.strip()
        match = header_regex.match(stripped)
        if match:
            if current_section and buffer:
                sections[current_section] = '\n'.join(buffer).strip()
            header_text = match.group(2)
            if 'å¼±é»èªªæ˜' in header_text or 'Explanation' in header_text:
                current_section = 'explanation'
            elif 'è§£æ±ºæ–¹æ³•' in header_text or 'ä¿®å¾©å»ºè­°' in header_text or 'Solution' in header_text:
                current_section = 'solution'
            elif 'åƒè€ƒè³‡æ–™' in header_text or 'Reference' in header_text:
                current_section = 'reference'
            buffer = []
            continue
        if current_section:
            buffer.append(line)
        else:
            if stripped and not sections['explanation']:
                current_section = 'explanation'
                buffer.append(line)
    
    if current_section and buffer:
        sections[current_section] = '\n'.join(buffer).strip()
    if not any(sections.values()):
        return {'solution': text}
    return sections

# [Enhanced] è¶…ç´šç‰ˆ Markdown æ¸²æŸ“å™¨ (å«è¡¨æ ¼æ”¯æ´)
def render_markdown(container, text):
    """
    å°‡ Markdown æ–‡å­—æ¸²æŸ“é€² docx çš„å®¹å™¨ä¸­ã€‚
    æ”¯æ´: è¡¨æ ¼(|), ç¨‹å¼ç¢¼(```), æ¨™é¡Œ(###), åˆ—è¡¨(-/1.), è¡Œå…§æ ¼å¼(**, `)
    """
    if not text: return

    lines = text.split('\n')
    in_code_block = False
    table_buffer = [] 

    def _render_inline(paragraph, text_content):
        token_pattern = re.compile(r'(\*\*.*?\*\*)|(`.*?`)')
        parts = token_pattern.split(text_content)
        for part in parts:
            if not part: continue
            if part.startswith("`") and part.endswith("`"):
                run = paragraph.add_run(part[1:-1])
                run.font.name = 'Courier New'
                run.font.color.rgb = RGBColor(180, 0, 0)
            elif part.startswith("**") and part.endswith("**"):
                run = paragraph.add_run(part[2:-2])
                run.bold = True
            else:
                paragraph.add_run(part)

    def _flush_table(buffer):
        if not buffer: return
        rows_data = [line.strip().strip('|').split('|') for line in buffer]
        rows_data = [[c.strip() for c in r] for r in rows_data]
        if not rows_data: return
        
        headers = None
        body_start = 0
        if len(rows_data) > 1 and all(set(c) <= set('-: ') for c in rows_data[1]):
            headers = rows_data[0]
            body_start = 2
        
        body_rows = rows_data[body_start:]
        all_rows = ([headers] if headers else []) + body_rows
        if not all_rows: return
        
        max_cols = max(len(r) for r in all_rows)
        table = container.add_table(rows=len(all_rows), cols=max_cols)
        table.style = 'Table Grid'
        
        curr_idx = 0
        if headers:
            for j, txt in enumerate(headers):
                if j < len(table.rows[curr_idx].cells):
                    p = table.rows[curr_idx].cells[j].paragraphs[0]
                    p.add_run(txt).bold = True
            curr_idx += 1
            
        for row in body_rows:
            for j, txt in enumerate(row):
                if j < len(table.rows[curr_idx].cells):
                    _render_inline(table.rows[curr_idx].cells[j].paragraphs[0], txt)
            curr_idx += 1
        container.add_paragraph("")

    for line in lines:
        stripped = line.strip()
        if not in_code_block and stripped.startswith('|') and stripped.endswith('|'):
            table_buffer.append(stripped)
            continue
        else:
            if table_buffer:
                _flush_table(table_buffer)
                table_buffer = []

        if not stripped: continue
        
        if stripped.startswith("```"):
            in_code_block = not in_code_block
            continue
        if in_code_block:
            p = container.add_paragraph()
            p.paragraph_format.left_indent = Inches(0.2)
            run = p.add_run(line)
            run.font.name = 'Courier New'
            run.font.size = Pt(9.5)
            run.font.color.rgb = RGBColor(80, 80, 80)
            continue
        
        if stripped.startswith("### ") or stripped.startswith("## "):
            p = container.add_paragraph()
            p.paragraph_format.space_before = Pt(6)
            run = p.add_run(stripped.lstrip("#").strip())
            run.bold = True
            run.font.size = Pt(13)
            run.font.color.rgb = RGBColor(46, 116, 181)
            continue

        p = None
        content = stripped
        if stripped.startswith("- ") or stripped.startswith("* "):
            try: p = container.add_paragraph(style='List Bullet')
            except: p = container.add_paragraph(style='List Paragraph')
            content = stripped[2:]
        elif re.match(r'^\d+\.\s', stripped):
            try: p = container.add_paragraph(style='List Number')
            except: p = container.add_paragraph(style='List Paragraph')
            content = re.sub(r'^\d+\.\s', '', stripped)
            
        if p is None: p = container.add_paragraph()
        _render_inline(p, content)

    if table_buffer: _flush_table(table_buffer)

# ==========================================
# 3. å ±å‘Šç”Ÿæˆä¸»é‚è¼¯
# ==========================================

def generate_word_report(json_path, output_path, ai_insights_path=None, company_name="Nextlink MSP"):
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"è®€å– JSON å¤±æ•—: {e}")
        return

    ai_data = {}
    if ai_insights_path and os.path.exists(ai_insights_path):
        try:
            with open(ai_insights_path, 'r', encoding='utf-8') as f:
                ai_data = json.load(f)
            print("âœ… æˆåŠŸè¼‰å…¥ AI åˆ†ææ•¸æ“šï¼")
        except: pass

    doc = Document()
    style = doc.styles['Normal']
    style.font.name = 'Microsoft JhengHei'
    style.font.size = Pt(11)
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'Microsoft JhengHei')

    # --- å°é¢ ---
    doc.add_heading(f'{company_name} - å¼±é»æƒæå ±å‘Š', 0)
    base_dir = os.path.dirname(json_path)
    logo_path = os.path.join(base_dir, 'logo.png')
    if os.path.exists(logo_path):
        try: doc.add_picture(logo_path, width=Inches(2.0))
        except: pass
    
    doc.add_paragraph(f"æƒæå·¥å…·: OWASP ZAP")
    doc.add_paragraph(f"ç”¢ç”Ÿæ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    scan_target = data.get('site', [{}])[0].get('@name', 'Unknown Target')
    doc.add_paragraph(f"æƒæç›®æ¨™: {scan_target}")
    doc.add_page_break()

    # --- æ‘˜è¦ ---
    doc.add_heading('1. æƒæçµæœæ‘˜è¦', level=1)
    sites = data.get('site', [])
    stats = {"High": 0, "Medium": 0, "Low": 0, "Informational": 0}
    for site in sites:
        for alert in site.get('alerts', []):
            risk_desc = alert.get('riskdesc', 'Info').split(' ')[0]
            if risk_desc in stats: stats[risk_desc] += 1
            else: stats["Informational"] += 1
    
    total_vulns = sum(stats.values())
    doc.add_paragraph(f"æœ¬æ¬¡æƒæå…±ç™¼ç¾ {total_vulns} å€‹æ½›åœ¨å¼±é»ã€‚é¢¨éšªåˆ†ä½ˆå¦‚ä¸‹ï¼š")

    chart_path = os.path.join(base_dir, "risk_chart.png")
    if generate_risk_chart(stats, chart_path):
        doc.add_picture(chart_path, width=Inches(4.0))
        if os.path.exists(chart_path): os.remove(chart_path)

    table = doc.add_table(rows=5, cols=2)
    table.style = 'Table Grid'
    hdr = table.rows[0].cells
    hdr[0].text, hdr[1].text = 'é¢¨éšªç­‰ç´š', 'æ•¸é‡ (Count)'
    set_table_header_style(hdr[0])
    set_table_header_style(hdr[1])

    def fill_row(idx, label, count, color):
        c = table.rows[idx].cells
        r1 = c[0].paragraphs[0].add_run(label)
        r2 = c[1].paragraphs[0].add_run(str(count))
        r1.bold = r2.bold = True
        r1.font.color.rgb = r2.font.color.rgb = color

    fill_row(1, "ğŸ”´ é«˜é¢¨éšª (High)", stats['High'], RGBColor(255, 0, 0))
    fill_row(2, "ğŸŸ  ä¸­é¢¨éšª (Medium)", stats['Medium'], RGBColor(255, 165, 0))
    fill_row(3, "ğŸŸ¡ ä½é¢¨éšª (Low)", stats['Low'], RGBColor(200, 200, 0))
    fill_row(4, "ğŸ”µ è³‡è¨Š (Info)", stats['Informational'], RGBColor(0, 0, 255))
    doc.add_paragraph("")

    if stats['High'] > 0:
        p = doc.add_paragraph()
        run = p.add_run(f"âš ï¸ æ³¨æ„ï¼šç³»çµ±å­˜åœ¨ {stats['High']} å€‹é«˜é¢¨éšªå¼±é»ï¼Œå»ºè­°ç«‹å³é€²è¡Œä¿®å¾©ï¼")
        run.bold = True
        run.font.color.rgb = RGBColor(255, 0, 0)
    doc.add_page_break()

    if ai_data.get('executive_summary'):
        doc.add_heading('ç”Ÿæˆå¼ AI ç¸½çµ', level=2)
        render_markdown(doc, ai_data['executive_summary'])
        doc.add_paragraph("")
    doc.add_page_break()

    # --- è©³æƒ… ---
    doc.add_heading('2. å¼±é»è©³æƒ…åˆ†æ', level=1)

    for site in sites:
        alerts = site.get('alerts', [])
        for alert in alerts:
            eng_name = alert.get('alert', 'Unknown Alert')
            risk_eng = alert.get('riskdesc', 'Info').split(' ')[0]
            desc = clean_html(alert.get('desc', ''))
            
            # æª¢æŸ¥ AI å…§å®¹
            ai_content = ai_data.get('solutions', {}).get(eng_name)
            parsed_ai = parse_ai_response(ai_content) if ai_content else None
            
            tw_name = translate_title(eng_name)
            tw_risk = RISK_MAPPING.get(risk_eng, risk_eng)

            doc.add_heading(tw_name, level=2)
            
            # å‹•æ…‹å»ºç«‹è¡¨æ ¼
            det_table = doc.add_table(rows=0, cols=2)
            det_table.style = 'Table Grid'
            det_table.columns[0].width = Inches(1.5)
            det_table.columns[1].width = Inches(5.0)

            def add_row(label, content, is_md=False, color=None):
                row = det_table.add_row()
                row.cells[0].text = label
                cell = row.cells[1]
                if is_md:
                    render_markdown(cell, content)
                else:
                    cell.text = content
                    if color:
                        run = cell.paragraphs[0].runs[0]
                        run.bold = True
                        run.font.color.rgb = color

            # 1. åŸºæœ¬è³‡è¨Š
            add_row("å¼±é»åŸå", eng_name)
            
            risk_color = None
            if "High" in risk_eng: risk_color = RGBColor(255, 0, 0)
            elif "Medium" in risk_eng: risk_color = RGBColor(255, 165, 0)
            add_row("é¢¨éšªç­‰ç´š", tw_risk, color=risk_color)
            
            # [Translation Feature] è‡ªå‹•ç¿»è­¯æè¿°
            # è‹¥æœ‰ AI è§£é‡‹å‰‡ç”¨ AIï¼Œå¦å‰‡ç”¨ç¿»è­¯éçš„åŸæè¿°
            if parsed_ai and parsed_ai.get('explanation'):
                # é€™è£¡ä¸éœ€è¦åšä»€éº¼ï¼Œä¸‹é¢æœƒåŠ  AI åˆ†ææ¬„ä½
                # ä½†åŸæœ¬çš„ "å¼±é»æè¿°" æ¬„ä½é‚„æ˜¯è¦å¡«ï¼Œæˆ‘å€‘ç”¨ç¿»è­¯éçš„ desc
                zh_desc = auto_translate(desc)
                add_row("å¼±é»æè¿°", zh_desc)
            else:
                zh_desc = auto_translate(desc)
                add_row("å¼±é»æè¿°", zh_desc)

            # 2. ä¿®å¾©å»ºè­°å€å¡Š (AI vs ZAP)
            if parsed_ai:
                if parsed_ai.get('explanation'):
                    add_row("å¼±é»åˆ†æ (AI)", parsed_ai['explanation'], is_md=True)
                
                sol_content = parsed_ai.get('solution') or ai_content
                add_row("ä¿®å¾©å»ºè­° (AI)", sol_content, is_md=True)
                
                if parsed_ai.get('reference'):
                    add_row("æŠ€è¡“åƒè€ƒ (AI)", parsed_ai['reference'], is_md=True)
                
                source_label = "ç”Ÿæˆå¼ AI å»ºè­°"
            else:
                # ZAP æ¨™æº–å»ºè­° (ä¹Ÿé€²è¡Œç¿»è­¯)
                solution_text = clean_html(alert.get('solution', ''))
                zh_solution = auto_translate(solution_text)
                add_row("ä¿®å¾©å»ºè­°", zh_solution)
                source_label = "ZAP æ¨™æº–å»ºè­°"

            # 3. ä¾†æºæ¨™ç¤º
            row = det_table.add_row()
            row.cells[0].text = "å»ºè­°ä¾†æº"
            p = row.cells[1].paragraphs[0]
            run = p.add_run(source_label)
            if parsed_ai:
                run.bold = True
                run.font.color.rgb = RGBColor(0, 112, 192)

            doc.add_paragraph("")

    try:
        doc.save(output_path)
        print(f"å ±å‘Šç”Ÿæˆå®Œç•¢ï¼å·²å„²å­˜è‡³: {output_path}")
    except Exception as e:
        print(f"å„²å­˜å¤±æ•—: {e}")

if __name__ == "__main__":
    DATA_DIR = "/app/data"
    json_file = os.path.join(DATA_DIR, 'ZAP-Report.json')
    ai_file = os.path.join(DATA_DIR, 'ai_insights.json')
    word_file = os.path.join(DATA_DIR, f'Scan_Report_{datetime.now().strftime("%Y%m%d")}.docx')
    
    if os.path.exists(json_file):
        generate_word_report(json_file, word_file, ai_insights_path=ai_file)
    else:
        print(f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {json_file}")